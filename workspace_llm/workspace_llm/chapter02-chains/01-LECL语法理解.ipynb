{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-11T08:38:49.092678Z",
     "start_time": "2025-12-11T08:38:46.199251Z"
    }
   },
   "source": [
    "# 引入依赖包\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "os.environ[\"OPENAI_BASE_URL\"] = os.getenv(\"DASHSCOPE_BASE_URL\")\n",
    "\n",
    "\n",
    "########核心代码############\n",
    "chat_model = ChatOpenAI(model=\"qwen-turbo\",\n",
    "                        temperature=0.7,    # 1=创造力\n",
    "                        max_tokens=100,)     # 最大数量\n",
    "\n",
    "joke_query = \"告诉我一个笑话。\"\n",
    "\n",
    "# 定义Json解析器\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "#以PromptTemplate为例\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=\"回答用户的查询\\n 满足的格式为{format_instructions}\\n 问题为{question}\\n\",\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "prompt = prompt_template.invoke(input={\"question\": joke_query})\n",
    "response = chat_model.invoke(prompt)\n",
    "print(response)\n",
    "\n",
    "json_result = parser.invoke(response)\n",
    "print(json_result)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='{\\n  \"response\": \"为什么数学书总是很忧郁？\\\\n因为它有太多的问题。\"\\n}' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 35, 'total_tokens': 59, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen-turbo', 'system_fingerprint': None, 'id': 'chatcmpl-20eb78b2-b183-4193-af4e-e6ce2cecc249', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b0c90-17bc-78d2-b91a-68681e3f1955-0' usage_metadata={'input_tokens': 35, 'output_tokens': 24, 'total_tokens': 59, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n",
      "{'response': '为什么数学书总是很忧郁？\\n因为它有太多的问题。'}\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T08:37:14.550599Z",
     "start_time": "2025-12-11T08:37:00.614722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "chat_model = OllamaLLM(\n",
    "    model = \"deepseek-r1:32b\",\n",
    "    validate_model_on_init=True,\n",
    "    reasoning=False,\n",
    "    base_url=\"http://localhost:12356\",\n",
    ")\n",
    "\n",
    "joke_query = \"告诉我一个笑话。\"\n",
    "\n",
    "# 定义Json解析器\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "#以PromptTemplate为例\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=\"回答用户的查询\\n 满足的格式为{format_instructions}\\n 问题为{question}\\n\",\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "prompt = prompt_template.invoke(input={\"question\": joke_query})\n",
    "response = chat_model.invoke(prompt)\n",
    "print(response)\n",
    "\n",
    "json_result = parser.invoke(response)\n",
    "print(json_result)"
   ],
   "id": "25e7e42f735bc33e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "好，我现在需要帮助用户找到一个笑话。首先，我应该考虑用户的需求是什么，他们可能只是想轻松一下或者寻找幽默的内容来分享给朋友。\n",
      "\n",
      "接下来，我要确保笑话的内容适合大多数听众，不会冒犯到任何人。所以，这个笑话应该是中性且普遍有趣的。\n",
      "\n",
      "考虑到常见的搞笑元素，动物和日常情境通常容易引起共鸣。于是，我想到用小明和他的宠物狗作为角色，这样容易让读者有代入感。\n",
      "\n",
      "然后，我需要一个有趣的情节转折点。小明把作业藏起来不让妈妈发现，这是一个常见的情节，容易让人联想到自己的经历或类似的情况，从而产生共鸣。\n",
      "\n",
      "最后，笑话的结尾要有意外性但又合乎情理，比如狗的行为导致小明被妈妈发现，这样既搞笑又有一定的逻辑性，不会让听众觉得突兀。\n",
      "\n",
      "总结一下，这个笑话结构清晰，情节简单有趣，适合各个年龄层的人。我应该用简短的语言表达出来，让用户一目了然，并且感到开心。\n",
      "</think>\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"joke\": \"有一天，小明把作业藏在了沙发下面，准备等妈妈睡着后偷偷拿出来写。可是他没想到的是，他的宠物狗也发现了这个秘密，并且决定帮他一起完成任务。结果第二天早上，小明的妈妈发现沙发上有一堆零食和一个写了几个字的本子，而小明正坐在地板上，对着一堆骨头发呆。\"\n",
      "}\n",
      "```\n",
      "{'joke': '有一天，小明把作业藏在了沙发下面，准备等妈妈睡着后偷偷拿出来写。可是他没想到的是，他的宠物狗也发现了这个秘密，并且决定帮他一起完成任务。结果第二天早上，小明的妈妈发现沙发上有一堆零食和一个写了几个字的本子，而小明正坐在地板上，对着一堆骨头发呆。'}\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "使用|符号以后的举例：",
   "id": "5cb284d1adda8c27"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T08:40:05.593564Z",
     "start_time": "2025-12-11T08:40:04.963928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 引入依赖包\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 初始化语言模型\n",
    "chat_model = ChatOpenAI(model=\"qwen-turbo\",\n",
    "                        temperature=0.7,    # 1=创造力\n",
    "                        max_tokens=100,)     # 最大数量\n",
    "\n",
    "joke_query = \"告诉我一个笑话。\"\n",
    "\n",
    "# 定义Json解析器\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "#以PromptTemplate为例\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=\"回答用户的查询\\n 满足的格式为{format_instructions}\\n 问题为{question}\\n\",\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "# 写法1：\n",
    "# prompt = prompt_template.invoke(input={\"question\":joke_query})\n",
    "# response = chat_model.invoke(prompt)\n",
    "# json_result = parser.invoke(response)\n",
    "\n",
    "# 正确的写法\n",
    "chain = prompt_template | chat_model | parser\n",
    "\n",
    "# 错误的写法\n",
    "# chain =  chat_model |  prompt_template | parser\n",
    "json_result = chain.invoke(input={\"question\": joke_query})\n",
    "print(json_result)"
   ],
   "id": "a260b64142a2eedb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': '为什么数学书总是很忧郁？\\n因为它有太多的问题。'}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T08:54:16.476140Z",
     "start_time": "2025-12-11T08:54:04.728137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 引入依赖包\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# 初始化语言模型\n",
    "chat_model = OllamaLLM(\n",
    "    model = \"deepseek-r1:32b\",\n",
    "    validate_model_on_init=True,\n",
    "    reasoning=False,\n",
    "    base_url=\"http://localhost:12356\",\n",
    ")\n",
    "\n",
    "joke_query = \"告诉我一个笑话。\"\n",
    "\n",
    "# 定义Json解析器\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "#以PromptTemplate为例\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=\"回答用户的查询\\n 满足的格式为{format_instructions}\\n 问题为{question}\\n\",\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "# 写法1：\n",
    "# prompt = prompt_template.invoke(input={\"question\":joke_query})\n",
    "# response = chat_model.invoke(prompt)\n",
    "# json_result = parser.invoke(response)\n",
    "\n",
    "# 正确的写法\n",
    "chain = prompt_template | chat_model | parser\n",
    "\n",
    "# 错误的写法\n",
    "# chain =  chat_model |  prompt_template | parser\n",
    "json_result = chain.invoke(input={\"question\": joke_query})\n",
    "print(json_result)"
   ],
   "id": "2e218bc4b6233197",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joke': '为什么大象不玩扑克牌？因为他们怕被‘抽’！'}\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
