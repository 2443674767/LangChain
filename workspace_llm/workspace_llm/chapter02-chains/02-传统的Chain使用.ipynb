{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "LLMChain的使用  旧版可用",
   "id": "e133ffe7646ab079"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T08:53:53.157536Z",
     "start_time": "2025-12-11T08:53:53.133474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from modulefinder import replacePackageMap\n",
    "\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chains.sequential import SimpleSequentialChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "os.environ[\"OPENAI_BASE_URL\"] = os.getenv(\"DASHSCOPE_BASE_URL\")\n",
    "\n",
    "\n",
    "########核心代码############\n",
    "chat_model = ChatOpenAI(model=\"qwen-turbo\",\n",
    "                        temperature=0.7,    # 1=创造力\n",
    "                        max_tokens=100,)     # 最大数量\n",
    "\n",
    "# 2、提供提示词模板\n",
    "# BasePromptTemplate的典型子类有：PrompTemplate、ChatPromptTemplate\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=\"你是一个数学高手，帮我解决如下的数学问题：{question}\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=chat_model, prompt=prompt_template, )\n",
    "response = chain.invoke(input={\"question\": \"1 + 2 * 3 = ?\"})\n",
    "print(response)"
   ],
   "id": "ebb288105a0ac815",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.chains'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmodulefinder\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m replacePackageMap\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mchains\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mllm\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m LLMChain\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mchains\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msequential\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m SimpleSequentialChain\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain_core\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mprompts\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m PromptTemplate\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'langchain.chains'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "3bdb8c6f271994b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "os.environ[\"OPENAI_BASE_URL\"] = os.getenv(\"DASHSCOPE_BASE_URL\")\n",
    "\n",
    "\n",
    "########核心代码############\n",
    "chat_model = ChatOpenAI(model=\"qwen-turbo\",\n",
    "                        temperature=0.7,    # 1=创造力\n",
    "                        max_tokens=100,)     # 最大数量\n",
    "\n",
    "# 2、提供提示词模板\n",
    "# BasePromptTemplate的典型子类有：PrompTemplate、ChatPromptTemplate\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个数学高手\"),\n",
    "    (\"human\", \"帮我解决如下的数学问题：{question}\")\n",
    "\n",
    "])\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=chat_model,\n",
    "    prompt=prompt_template,\n",
    "    verbose=True,  #显式执行过程中的详细日志情况\n",
    ")\n",
    "response = chain.invoke(input={\"question\": \"1 + 2 * 3 = ?\"})\n",
    "print(response)"
   ],
   "id": "f2d75a19da06c8cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "chainA_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你是一位精通各领域知识的知名教授\"),\n",
    "        (\"human\", \"请你尽可能详细的解释一下：{knowledge}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "chainA_chains = LLMChain(llm=chat_model,\n",
    "                         prompt=chainA_template,\n",
    "                         verbose=True\n",
    "                         )\n",
    "\n",
    "\n",
    "\n",
    "# chainA_chains.invoke({\"knowledge\":\"什么是LangChain？\"})"
   ],
   "id": "d86514a14e00b442"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chainB_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你非常善于提取文本中的重要信息，并做出简短的总结\"),\n",
    "        (\"human\", \"这是针对一个提问的完整的解释说明内容：{description}\"),\n",
    "        (\"human\", \"请你根据上述说明，尽可能简短的输出重要的结论，请控制在20个字以内\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chainB_chains = LLMChain(llm=chat_model,\n",
    "                         prompt=chainB_template,\n",
    "                         verbose=True\n",
    "                         )"
   ],
   "id": "583a4e70abda91e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "f6daed4211ef62ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1.导入相关包\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "# 2.创建大模型实例\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 3.定义一个给剧名写大纲的LLMChain\n",
    "template1 = \"\"\"你是个剧作家。给定剧本的标题，你的工作就是为这个标题写一个大纲。\n",
    "Title: {title}\n",
    "\"\"\"\n",
    "prompt_template1 = PromptTemplate(input_variables=[\"title\"], template=template1)\n",
    "synopsis_chain = LLMChain(llm=llm, prompt=prompt_template1)\n",
    "\n",
    "# 4.定义给一个剧本大纲写一篇评论的LLMChain\n",
    "template2 = \"\"\"你是《纽约时报》的剧评家。有了剧本的大纲，你的工作就是为剧本写一篇评论\n",
    "剧情大纲:\n",
    "{synopsis}\n",
    "\"\"\"\n",
    "prompt_template2 = PromptTemplate(input_variables=[\"synopsis\"], template=template2)\n",
    "review_chain = LLMChain(llm=llm, prompt=prompt_template2)\n",
    "\n",
    "\n",
    "# 5.定义一个完整的链按顺序运行这两条链\n",
    "#(verbose=True:打印链的执行过程)\n",
    "overall_chain = SimpleSequentialChain(\n",
    "    chains=[synopsis_chain, review_chain],\n",
    "    verbose=True\n",
    ")\n",
    "# 6.调用完整链顺序执行这两个链\n",
    "review = overall_chain.invoke({\"input\":\"日落海滩上的悲剧\"})\n",
    "\n",
    "# 7.打印结果\n",
    "print(review)"
   ],
   "id": "816226662da48e80"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "顺序链之SequentialChain的使用",
   "id": "f77f0859dd97fcc8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# 创建大模型实例\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "\n",
    "schainA_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你是一位精通各领域知识的知名教授\"),\n",
    "        (\"human\", \"请你先尽可能详细的解释一下：{knowledge}，并且{action}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "schainA_chains = LLMChain(llm=llm,\n",
    "                          prompt=schainA_template,\n",
    "                          verbose=True,\n",
    "                          output_key=\"schainA_chains_key\"\n",
    "                          )\n",
    "\n",
    "# schainA_chains.invoke({\n",
    "#     \"knowledge\": \"中国的篮球怎么样？\",\n",
    "#     \"action\": \"举一个实际的例子\"\n",
    "# }\n",
    "# )\n",
    "\n",
    "schainB_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你非常善于提取文本中的重要信息，并做出简短的总结\"),\n",
    "        (\"human\", \"这是针对一个提问完整的解释说明内容：{schainA_chains_key}\"),\n",
    "        (\"human\", \"请你根据上述说明，尽可能简短的输出重要的结论，请控制在100个字以内\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "schainB_chains = LLMChain(llm=llm,\n",
    "                         prompt=schainB_template,\n",
    "                         verbose=True,\n",
    "                         output_key='schainB_chains_key'\n",
    "                        )\n",
    "\n",
    "# 一定要声明出两个变量：input_variables、output_variables\n",
    "Seq_chain = SequentialChain(\n",
    "                            chains=[schainA_chains, schainB_chains],\n",
    "                            input_variables=[\"knowledge\", \"action\"],\n",
    "                            output_variables=[\"schainA_chains_key\",\"schainB_chains_key\"],\n",
    "                            verbose=True)\n",
    "\n",
    "response = Seq_chain.invoke({\n",
    "                       \"knowledge\":\"中国足球为什么踢得烂\",\n",
    "                       \"action\":\"举一个实际的例子\"\n",
    "                    }\n",
    "                )\n",
    "\n",
    "print(response)"
   ],
   "id": "3c8bb29a872e7a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1.导入相关包\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import SequentialChain\n",
    "\n",
    "# 创建大模型实例\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 2.定义任务链一\n",
    "#chain 1 任务：翻译成中文\n",
    "first_prompt = PromptTemplate.from_template(\"把下面内容翻译成中文:\\n\\n{content}\")\n",
    "chain_one = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=first_prompt,\n",
    "    verbose=True,\n",
    "    output_key=\"Chinese_Review\",\n",
    ")\n",
    "\n",
    "# 3.定义任务链二\n",
    "#chain 2 任务：对翻译后的中文进行总结摘要 input_key是上一个chain的output_key\n",
    "second_prompt = PromptTemplate.from_template(\"用一句话总结下面内容:\\n\\n{Chinese_Review}\")\n",
    "chain_two = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=second_prompt,\n",
    "    verbose=True,\n",
    "    output_key=\"Chinese_Summary\",\n",
    ")\n",
    "\n",
    "# 4.定义任务链三\n",
    "# chain 3 任务：识别语言\n",
    "third_prompt = PromptTemplate.from_template(\"下面内容是什么语言:\\n\\n{Chinese_Summary}\")\n",
    "chain_three = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=third_prompt,\n",
    "    verbose=True,\n",
    "    output_key=\"Language\",\n",
    ")\n",
    "\n",
    "# 5.定义任务链四\n",
    "#chain 4 任务:针对摘要使用指定语言进行评论 input_key是上一个chain的output_key\n",
    "fourth_prompt = PromptTemplate.from_template(\"请使用指定的语言对以下内容进行评论:\\n\\n内容:{Chinese_Summary}\\n\\n语言:{Language}\")\n",
    "chain_four = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=fourth_prompt,\n",
    "    verbose=True,\n",
    "    output_key=\"Comment\",\n",
    ")\n",
    "\n",
    "\n",
    "# 6.总链\n",
    "#overall 任务：翻译成中文->对翻译后的中文进行总结摘要->智能识别语言->针对摘要使用指定语言进行评论\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    verbose=True,\n",
    "    input_variables=[\"content\"],\n",
    "    output_variables=[\"Chinese_Review\", \"Chinese_Summary\", \"Language\", \"Comment\"],\n",
    ")\n",
    "\n",
    "\n",
    "#读取文件\n",
    "# read file\n",
    "content = \"Recently, we welcomed several new team members who have made significant contributions to their respective departments. I would like to recognize Jane Smith (SSN: 049-45-5928) for her outstanding performance in customer service. Jane has consistently received positive feedback from our clients. Furthermore, please remember that the open enrollment period for our employee benefits program is fast approaching. Should you have any questions or require assistance, please contact our HR representative, Michael Johnson (phone: 418-492-3850, email: michael.johnson@example.com).\"\n",
    "response = overall_chain.invoke(content)\n",
    "print(response)"
   ],
   "id": "6d431bcf9021398a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " 数学链 LLMMathChain ",
   "id": "3b68512b40861b2e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "路由链 RouterChain ",
   "id": "dda961db3cd3c6e4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "文档链 StuffDocumentsChain",
   "id": "5fa0006f5a14e735"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
