{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "字符串输出解析器 StrOutputParser",
   "id": "a4926a8a273fe92c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T05:27:59.646759Z",
     "start_time": "2025-12-11T05:27:52.601634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1、获取大模型\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.output_parsers import StrOutputParser, XMLOutputParser\n",
    "\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_core.utils import pre_init\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "os.environ[\"OPENAI_BASE_URL\"] = os.getenv(\"DASHSCOPE_BASE_URL\")\n",
    "\n",
    "\n",
    "########核心代码############\n",
    "chat_model = ChatOpenAI(model=\"qwen-turbo\",\n",
    "                        temperature=0.7,    # 1=创造力\n",
    "                        max_tokens=100,)     # 最大数量\n",
    "\n",
    "# 2、调用大模型\n",
    "response = chat_model.invoke(\"什么是大语言模型？\")\n",
    "# print(type(response))   #AIMessage\n",
    "\n",
    "#3、如何获取一个字符串的输出结果呢？\n",
    "# 方式1：自己调用输出结果的content\n",
    "# print(response.content)\n",
    "\n",
    "# 方式2：使用StrOutputParser\n",
    "parser = StrOutputParser()\n",
    "str_response = parser.invoke(response)\n",
    "print(type(str_response))  #<class 'str'>\n",
    "print(str_response)\n"
   ],
   "id": "b938d59283de7664",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "大语言模型（Large Language Model，简称 LLM）是一种基于深度学习的自然语言处理（NLP）模型，它通过在大量文本数据上进行训练，能够理解和生成人类语言。这些模型通常包含数十亿甚至数千亿个参数，因此被称为“大”语言模型。\n",
      "\n",
      "### 大语言模型的核心特点包括：\n",
      "\n",
      "1. **大规模参数**：  \n",
      "   大语言模型通常具有庞大的参数量，这使得它们能够捕捉更复杂的语言模式和语义关系。\n",
      "\n",
      "2. **预训练与微调**：  \n",
      "   这些模型通常先在大量文本数据上进行**预训练**，学习语言的通用表示；然后在特定任务上进行**微调**，以适应具体的应用场景，如问答、文本生成、翻译等。\n",
      "\n",
      "3. **强大的语言理解能力**：  \n",
      "   大语言模型可以理解上下文、识别实体、推理逻辑，并能生成连贯、自然的文本。\n",
      "\n",
      "4. **多任务处理能力**：  \n",
      "   一个大语言模型可以执行多种任务，例如：\n",
      "   - 文本生成（如写故事、写代码）\n",
      "   - 问答系统\n",
      "   - 翻译\n",
      "   - 情感分析\n",
      "   - 对话系统（如聊天机器人）\n",
      "\n",
      "5. **零样本/少样本学习能力**：  \n",
      "   即使没有经过特定任务的微调，大语言模型也能在少量示例的情况下完成新任务。\n",
      "\n",
      "---\n",
      "\n",
      "### 常见的大语言模型包括：\n",
      "\n",
      "- **GPT系列**（如 GPT-3、GPT-4）——由 OpenAI 开发。\n",
      "- **BERT**、**RoBERTa**、**ALBERT** —— 由 Google 开发的预训练模型。\n",
      "- **T5**、**BART** —— 由 Google 和 Facebook 开发的序列到序列模型。\n",
      "- **LLaMA**、**ChatGLM**、**Qwen（通义千问）** —— 由 Meta、智普清言、阿里巴巴等公司开发的大规模语言模型。\n",
      "\n",
      "---\n",
      "\n",
      "### 应用场景\n",
      "\n",
      "大语言模型广泛应用于以下领域：\n",
      "\n",
      "- **智能客服**：自动回答用户问题。\n",
      "- **内容创作**：生成文章、故事、剧本等。\n",
      "- **代码生成与理解**：辅助程序员编写或理解代码。\n",
      "- **教育**：个性化学习、答疑解惑。\n",
      "- **数据分析**：从文本中提取信息、生成报告。\n",
      "- **虚拟助手**：如 Siri、Alexa、小爱同学等。\n",
      "\n",
      "---\n",
      "\n",
      "### 总结\n",
      "\n",
      "**大语言模型**是人工智能领域的一项重要技术，它通过强大的语言理解和生成能力，改变了人机交互的方式，成为许多现代应用的核心技术之一。随着技术的不断进步，大语言模型的能力还在不断提升，未来将在更多领域发挥重要作用。\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "JsonOutputParser : Json输出解析器",
   "id": "f09eaeed11989f99"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T05:38:39.263651Z",
     "start_time": "2025-12-11T05:38:38.008884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_model = ChatOpenAI(model=\"qwen-turbo\",\n",
    "                        temperature=0.7,    # 1=创造力\n",
    "                        max_tokens=100,)     # 最大数量\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个靠谱的{role}\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# 正确的：\n",
    "prompt = chat_prompt_template.invoke(\n",
    "    input={\"role\": \"人工智能专家\", \"question\": \"人工智能用英文怎么说？问题用q表示，答案用a表示，返回一个JSON格式的数据\"})\n",
    "\n",
    "# 错误的：\n",
    "# prompt = chat_prompt_template.invoke(input={\"role\":\"人工智能专家\",\"question\":\"人工智能用英文怎么说？\"})\n",
    "\n",
    "response = chat_model.invoke(prompt)\n",
    "print(response.content)\n",
    "\n",
    "# 获取一个JsonOutputParser的实例\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "json_result = parser.invoke(response)\n",
    "print(json_result)"
   ],
   "id": "b9b042aca5189e84",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Q\": \"What is the English word for artificial intelligence?\",\n",
      "  \"A\": \"Artificial intelligence is translated into English as 'artificial intelligence'.\"\n",
      "}\n",
      "{'Q': 'What is the English word for artificial intelligence?', 'A': \"Artificial intelligence is translated into English as 'artificial intelligence'.\"}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "方式2：",
   "id": "9aca4ba374f9c129"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T05:39:10.443049Z",
     "start_time": "2025-12-11T05:39:10.439037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "parser = JsonOutputParser()\n",
    "\n",
    "print(parser.get_format_instructions())"
   ],
   "id": "abee9520e1d37fd7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return a JSON object.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T05:42:49.494801Z",
     "start_time": "2025-12-11T05:42:48.498459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 引入依赖包\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 初始化语言模型\n",
    "chat_model = ChatOpenAI(model=\"qwen-turbo\",\n",
    "                        temperature=0.7,    # 1=创造力\n",
    "                        max_tokens=100,)     # 最大数量\n",
    "\n",
    "joke_query = \"告诉我一个笑话。\"\n",
    "\n",
    "# 定义Json解析器\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "#以PromptTemplate为例\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=\"回答用户的查询\\n 满足的格式为{format_instructions}\\n 问题为{question}\\n\",\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "prompt = prompt_template.invoke(input={\"question\": joke_query})\n",
    "response = chat_model.invoke(prompt)\n",
    "print(response)\n",
    "\n",
    "json_result = parser.invoke(response)\n",
    "print(json_result)"
   ],
   "id": "13b09edf8729b85d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='{\\n  \"response\": \"为什么数学书总是很忧郁？\\\\n因为它有太多的问题。\"\\n}' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 35, 'total_tokens': 59, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'qwen-turbo', 'system_fingerprint': None, 'id': 'chatcmpl-280f23b4-960f-4aa5-856c-d7641438675b', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--38dee115-745c-4da8-91a1-b76507f16f1f-0' usage_metadata={'input_tokens': 35, 'output_tokens': 24, 'total_tokens': 59, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n",
      "{'response': '为什么数学书总是很忧郁？\\n因为它有太多的问题。'}\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T05:47:52.285907Z",
     "start_time": "2025-12-11T05:47:51.116843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_model = ChatOpenAI(model=\"qwen-turbo\",\n",
    "                        temperature=0.7,    # 1=创造力\n",
    "                        max_tokens=100,)     # 最大数量\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个靠谱的{role}\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# 获取一个JsonOutputParser的实例\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# 写法1：\n",
    "# prompt = chat_prompt_template.invoke(input={\"role\":\"人工智能专家\",\"question\":\"人工智能用英文怎么说？问题用q表示，答案用a表示，返回一个JSON格式的数据\"})\n",
    "#\n",
    "# response = chat_model.invoke(prompt)\n",
    "#\n",
    "# json_result = parser.invoke(response)\n",
    "# print(json_result)\n",
    "\n",
    "\n",
    "# 写法2：\n",
    "chain = chat_prompt_template | chat_model | parser\n",
    "json_result1 = chain.invoke(\n",
    "    input={\"role\": \"人工智能专家\", \"question\": \"人工智能用英文怎么说？问题用q表示，答案用a表示，返回一个JSON格式的数据\"})\n",
    "print(json_result1)"
   ],
   "id": "b29ef68ae5b7d142",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'q': 'What is the English word for artificial intelligence?', 'a': \"Artificial intelligence is called 'artificial intelligence' in English.\"}\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "XMLOutputParser XML输出解析器的使用",
   "id": "3d4b9a668482d946"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T05:54:36.416253Z",
     "start_time": "2025-12-11T05:54:34.820239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chat_model = ChatOpenAI(model=\"qwen-turbo\",\n",
    "                        temperature=0.7,    # 1=创造力\n",
    "                        max_tokens=100,)     # 最大数量\n",
    "\n",
    "actor_query = \"周星驰的简短电影记录\"\n",
    "response = chat_model.invoke(f\"请生成{actor_query}，将影片附在<movie></movie>标签中\")\n",
    "\n",
    "print(type(response))\n",
    "print(response.content)"
   ],
   "id": "556d28033169f9e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "<movie>\n",
      "《唐伯虎点秋香》是周星驰于1993年自导自演的一部喜剧电影，讲述了唐伯虎为追求秋香而混入华府的故事。影片以无厘头风格为主，充满夸张的表演和搞笑桥段，是周星驰经典作品之一。\n",
      "</movie>\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T05:54:56.776060Z",
     "start_time": "2025-12-11T05:54:56.772553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers.xml import XMLOutputParser\n",
    "\n",
    "parser = XMLOutputParser()\n",
    "print(parser.get_format_instructions())"
   ],
   "id": "af25be20eb9c22d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a XML file.\n",
      "1. Output should conform to the tags below.\n",
      "2. If tags are not given, make them on your own.\n",
      "3. Remember to always open and close all the tags.\n",
      "\n",
      "As an example, for the tags [\"foo\", \"bar\", \"baz\"]:\n",
      "1. String \"<foo>\n",
      "   <bar>\n",
      "      <baz></baz>\n",
      "   </bar>\n",
      "</foo>\" is a well-formatted instance of the schema.\n",
      "2. String \"<foo>\n",
      "   <bar>\n",
      "   </foo>\" is a badly-formatted instance.\n",
      "3. String \"<foo>\n",
      "   <tag>\n",
      "   </tag>\n",
      "</foo>\" is a badly-formatted instance.\n",
      "\n",
      "Here are the output tags:\n",
      "```\n",
      "None\n",
      "```\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T05:55:35.753467Z",
     "start_time": "2025-12-11T05:55:33.236038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1.导入相关包\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 2. 初始化语言模型\n",
    "chat_model = ChatOpenAI(model=\"qwen-turbo\",\n",
    "                        temperature=0.7,    # 1=创造力\n",
    "                        max_tokens=100,)     # 最大数量\n",
    "\n",
    "# 3.测试模型的xml解析效果\n",
    "actor_query = \"生成汤姆·汉克斯的简短电影记录,使用中文回复\"\n",
    "\n",
    "# 4.定义XMLOutputParser对象\n",
    "parser = XMLOutputParser()\n",
    "\n",
    "# 5. 生成提示词模板\n",
    "prompt_template1 = PromptTemplate.from_template(\n",
    "    template=\"用户的问题：{query}\\n使用的格式：{format_instructions}\"\n",
    ")\n",
    "\n",
    "prompt_template2 = prompt_template1.partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "\n",
    "response = chat_model.invoke(prompt_template2.invoke(input={\"query\": actor_query}))\n",
    "print(response.content)\n"
   ],
   "id": "5aabb2b1f53f8202",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```xml\n",
      "<filmography>\n",
      "    <movie>\n",
      "        <title>阿甘正传</title>\n",
      "        <year>1994</year>\n",
      "        <role>阿甘</role>\n",
      "    </movie>\n",
      "    <movie>\n",
      "        <title>拯救大兵瑞恩</title>\n",
      "        <year>1998</year>\n",
      "        <role>詹姆斯·瑞恩</role>\n",
      "    </movie>\n",
      "    <movie>\n",
      "        <title>绿里奇迹</title>\n",
      "        <year>1999</year>\n",
      "        <role>保尔·艾吉</role>\n",
      "    </movie>\n",
      "    <movie>\n",
      "        <title>云图</title>\n",
      "        <year>2012</year>\n",
      "        <role>多个角色</role>\n",
      "    </movie>\n",
      "</filmography>\n",
      "```\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T05:59:12.176681Z",
     "start_time": "2025-12-11T05:59:12.135763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "xml_result = parser.invoke(response)\n",
    "print(xml_result)"
   ],
   "id": "383fead2fa6c6b41",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filmography': [{'movie': [{'title': '阿甘正传'}, {'year': '1994'}, {'role': '阿甘'}]}, {'movie': [{'title': '拯救大兵瑞恩'}, {'year': '1998'}, {'role': '詹姆斯·瑞恩'}]}, {'movie': [{'title': '绿里奇迹'}, {'year': '1999'}, {'role': '保尔·艾吉'}]}, {'movie': [{'title': '云图'}, {'year': '2012'}, {'role': '多个角色'}]}]}\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "列表解析器 CommaSeparatedListOutputParser",
   "id": "3e40fa3f3cdd267e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T06:04:15.610096Z",
     "start_time": "2025-12-11T06:04:15.603480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "# 返回一些指令或模板，这些指令告诉系统如何解析或格式化输出数据\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(format_instructions)\n",
    "\n",
    "messages = \"大象,猩猩,狮子\"\n",
    "result = output_parser.parse(messages)\n",
    "print(result)\n",
    "print(type(result))"
   ],
   "id": "1cd064e759814d0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n",
      "['大象', '猩猩', '狮子']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T06:32:09.112275Z",
     "start_time": "2025-12-11T06:32:07.801543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "# 初始化语言模型\n",
    "chat_model = ChatOpenAI(model=\"qwen-turbo\",\n",
    "                        temperature=0.7,    # 1=创造力\n",
    "                        max_tokens=100,)     # 最大数量\n",
    "\n",
    "# 创建解析器\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "# 创建LangChain提示模板\n",
    "chat_prompt = PromptTemplate.from_template(\n",
    "    \"生成5个关于{text}的列表.\\n\\n{format_instructions}\",\n",
    "    partial_variables={\n",
    "    \"format_instructions\": output_parser.get_format_instructions()\n",
    "    })\n",
    "\n",
    "# 提示模板与输出解析器传递输出\n",
    "# chat_prompt = chat_prompt.partial(format_instructions=output_parser.get_format_instructions())\n",
    "\n",
    "# 将提示和模型合并以进行调用\n",
    "chain = chat_prompt | chat_model | output_parser\n",
    "res = chain.invoke({\"text\": \"电影\"})\n",
    "print(res)\n",
    "print(type(res))"
   ],
   "id": "e7b82d2119e8b6b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['星际穿越', '肖申克的救赎', '阿甘正传', '盗梦空间', '泰坦尼克号']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "日期解析器 DatetimeOutputParser",
   "id": "60c871e756539d99"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T06:32:04.807958Z",
     "start_time": "2025-12-11T06:32:04.805290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "\n",
    "output_parser = DatetimeOutputParser()\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(format_instructions)"
   ],
   "id": "2aecb20727b5645f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\n",
      "\n",
      "Examples: 1871-02-03T01:55:36.792831Z, 0525-06-11T23:29:04.907217Z, 0296-03-27T12:34:15.110586Z\n",
      "\n",
      "Return ONLY this string, no other words!\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T06:32:00.019711Z",
     "start_time": "2025-12-11T06:31:58.907599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts.chat import HumanMessagePromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "\n",
    "chat_model = ChatOpenAI(model=\"qwen-turbo\",\n",
    "                        temperature=0.7,    # 1=创造力\n",
    "                        max_tokens=100,)     # 最大数量\n",
    "\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"{format_instructions}\"),\n",
    "    (\"human\", \"{request}\")\n",
    "])\n",
    "\n",
    "output_parser = DatetimeOutputParser()\n",
    "\n",
    "# 方式1：\n",
    "# model_request = chat_prompt.format_messages(\n",
    "#     request=\"中华人民共和国是什么时候成立的\",\n",
    "#     format_instructions=output_parser.get_format_instructions()\n",
    "# )\n",
    "\n",
    "# response = chat_model.invoke(model_request)\n",
    "# result = output_parser.invoke(response)\n",
    "# print(result)\n",
    "# print(type(result))\n",
    "\n",
    "# 方式2：\n",
    "chain = chat_prompt | chat_model | output_parser\n",
    "resp = chain.invoke({\"request\":\"中华人民共和国是什么时候成立的\",\n",
    "                     \"format_instructions\":output_parser.get_format_instructions()})\n",
    "print(resp)\n",
    "print(type(resp))"
   ],
   "id": "f2e247d36bf4ca04",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1949-10-01 00:00:00\n",
      "<class 'datetime.datetime'>\n"
     ]
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
