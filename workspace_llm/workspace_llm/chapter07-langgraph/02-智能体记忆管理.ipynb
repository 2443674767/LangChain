{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e5ca1053b82fa983"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "cbd472deba40d731"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T03:08:40.473559Z",
     "start_time": "2025-12-17T03:08:39.791553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dotenv\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "# from langchain.agents import create_react_agent\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# 加载环境变量配置文件\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# 初始化本地大语言模型，模型名称和推理模式\n",
    "llm = ChatOllama(\n",
    "    # model=\"deepseek-r1:32b\",\n",
    "    model=\"llama3.1:8b\",\n",
    "    base_url=\"http://localhost:12356\"\n",
    ")\n",
    "\n",
    "# 定义工具列表，\n",
    "tools = []\n",
    "# 定义短期记忆使用内存（生产可以换 RedisSaver/PostgresSaver）\n",
    "checkpointer = InMemorySaver()\n",
    "# 创建ReAct代理，结合语言模型和工具函数\n",
    "agent = create_react_agent(model=llm, tools=tools, checkpointer=checkpointer)\n",
    "# 多轮对话配置，同一 thread_id 即同一会话\n",
    "config = {\"configurable\": {\"thread_id\": \"user-001\"}}\n",
    "\n",
    "msg1 = agent.invoke({\"messages\": [(\"user\", \"你好，我叫joker，喜欢学习。\")]}, config)\n",
    "msg1[\"messages\"][-1].pretty_print()\n",
    "\n",
    "# 6. 第二轮（继续同一 thread）\n",
    "msg2 = agent.invoke({\"messages\": [(\"user\", \"我叫什么？我喜欢做什么？\")]}, config)\n",
    "msg2[\"messages\"][-1].pretty_print()"
   ],
   "id": "bfe2f42c2071c3ff",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xydc\\AppData\\Local\\Temp\\ipykernel_15040\\1541617333.py:22: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  agent = create_react_agent(model=llm, tools=tools, checkpointer=checkpointer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "你好joker!很高兴认识你！学习是一件很棒的事情，你想学什么东西呢？\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "你刚才说过的！\n",
      "\n",
      "你叫: Joker\n",
      "你喜欢做：学习\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "27bd2d32c7c90434"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T03:08:35.195543Z",
     "start_time": "2025-12-17T03:08:34.093690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import TypedDict, Annotated\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.constants import START, END\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "class State(TypedDict):\n",
    "    \"\"\"\n",
    "    定义图结构中节点间传递的状态结构\n",
    "\n",
    "    Attributes:\n",
    "        messages: 消息列表，使用add_messages函数进行合并\n",
    "    \"\"\"\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# 创建状态图构建器\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# 初始化本地大语言模型，配置基础URL、模型名称和推理模式\n",
    "llm = ChatOllama(\n",
    "    # model=\"deepseek-r1:32b\",\n",
    "    model=\"llama3.1:8b\",\n",
    "    base_url=\"http://localhost:12356\"\n",
    ")\n",
    "\n",
    "def chatbot(state: State):\n",
    "    \"\"\"\n",
    "    聊天机器人节点函数，处理输入消息并生成回复\n",
    "\n",
    "    Args:\n",
    "        state (State): 包含消息历史的状态字典\n",
    "\n",
    "    Returns:\n",
    "        dict: 包含新生成消息的字典，格式为{\"messages\": [回复消息]}\n",
    "    \"\"\"\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "# 将聊天机器人节点添加到图中\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# 添加从开始节点到聊天机器人节点的边\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# 添加从聊天机器人节点到结束节点的边\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "# 创建内存保存器用于保存对话状态\n",
    "memory = MemorySaver()\n",
    "\n",
    "# 编译图结构并设置检查点保存器\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "# 绘制图结构并保存为PNG图片\n",
    "graph.get_graph().draw_png('./graph6.png')\n",
    "\n",
    "# 配置对话线程ID\n",
    "config = {\"configurable\": {\"thread_id\": \"chat-1\"}}\n",
    "\n",
    "# 第一次对话：发送初始消息\n",
    "msg1 = graph.invoke({\"messages\": [\"你好，我叫joker，喜欢学习。\"]}, config=config)\n",
    "msg1[\"messages\"][-1].pretty_print()\n",
    "\n",
    "# 第二次对话：基于上下文询问用户信息\n",
    "msg2 = graph.invoke({\"messages\": [\"我叫什么？我喜欢做什么？\"]}, config=config)\n",
    "msg2[\"messages\"][-1].pretty_print()\n"
   ],
   "id": "6842d254e6ae5ccc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "哈哈，你好！很高兴认识你，Joker！学到新知识真的是很棒的习惯。你想学习什么内容呢？我们可以一起讨论或分享一些有趣的信息。\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "你之前已经告诉我的了！你的名字是 Joker，你喜欢学习！\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "长期记忆+跨线程召回",
   "id": "1ff27e12a321dc3f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T03:08:28.606416Z",
     "start_time": "2025-12-17T03:08:27.377620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import uuid\n",
    "from typing import TypedDict, Annotated\n",
    "import dotenv\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.constants import END, START\n",
    "from langgraph.graph import StateGraph, MessagesState, add_messages\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langgraph.store.base import BaseStore\n",
    "\n",
    "# 加载环境变量配置\n",
    "dotenv.load_dotenv()\n",
    "# 初始化本地大语言模型，配置模型名称和推理模式\n",
    "model = ChatOllama(\n",
    "    # model=\"deepseek-r1:32b\",\n",
    "    model=\"llama3.1:8b\",\n",
    "    base_url=\"http://localhost:12356\"\n",
    ")\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    \"\"\"\n",
    "    定义图中状态的数据结构。\n",
    "\n",
    "    属性:\n",
    "        messages (Annotated[list, add_messages]): 使用 add_messages 合并的消息列表。\n",
    "    \"\"\"\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "def save_memory(store: BaseStore, user_id: str, content: str):\n",
    "    \"\"\"\n",
    "    将用户输入的内容保存为记忆。\n",
    "\n",
    "    参数:\n",
    "        store (BaseStore): 存储系统的实例，用于持久化数据。\n",
    "        user_id (str): 用户唯一标识符。\n",
    "        content (str): 需要存储的文本内容。\n",
    "    \"\"\"\n",
    "    namespace = (\"memories\", user_id)\n",
    "    store.put(namespace, str(uuid.uuid4()), {\"data\": content})\n",
    "\n",
    "\n",
    "def recall_memories(store: BaseStore, user_id: str, query: str, limit: int = 5):\n",
    "    \"\"\"\n",
    "    根据查询语句检索与用户相关的记忆。\n",
    "\n",
    "    参数:\n",
    "        store (BaseStore): 存储系统的实例。\n",
    "        user_id (str): 用户唯一标识符。\n",
    "        query (str): 查询关键词或句子。\n",
    "        limit (int, optional): 返回的记忆条数上限，默认是 5 条。\n",
    "\n",
    "    返回:\n",
    "        list[str]: 匹配的记忆内容列表。\n",
    "    \"\"\"\n",
    "    namespace = (\"memories\", user_id)\n",
    "    memories = store.search(namespace, query=query, limit=limit)\n",
    "    return [m.value[\"data\"] for m in memories]\n",
    "\n",
    "\n",
    "def chatbot(state: MessagesState, config: RunnableConfig, *, store: BaseStore):\n",
    "    \"\"\"\n",
    "    聊天机器人主逻辑节点函数。\n",
    "\n",
    "    参数:\n",
    "        state (MessagesState): 当前对话的状态信息，包括历史消息等。\n",
    "        config (RunnableConfig): 运行时配置信息，如线程ID、用户ID等。\n",
    "        store (BaseStore): 用于读取和写入用户记忆的存储接口。\n",
    "\n",
    "    返回:\n",
    "        dict: 更新后的消息状态字典。\n",
    "    \"\"\"\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # 检索历史记忆\n",
    "    query = state[\"messages\"][-1].content\n",
    "    related_memories = recall_memories(store, user_id, query)\n",
    "\n",
    "    # 构造系统提示\n",
    "    system_msg = (\n",
    "        \"你是一个友好的聊天助手。\\n\"\n",
    "        f\"以下是关于用户的记忆:\\n{chr(10).join(related_memories) if related_memories else '暂无'}\"\n",
    "    )\n",
    "\n",
    "    # 保存当前消息到记忆\n",
    "    save_memory(store, user_id, query)\n",
    "\n",
    "    # 调用模型生成回复\n",
    "    response = model.invoke(\n",
    "        [{\"role\": \"system\", \"content\": system_msg}] + state[\"messages\"]\n",
    "    )\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# 创建状态图并定义流程\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(chatbot)\n",
    "builder.add_edge(START, \"chatbot\")\n",
    "builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "# 初始化检查点和存储组件\n",
    "checkpointer = InMemorySaver()\n",
    "store = InMemoryStore()\n",
    "\n",
    "# 编译构建最终可运行的图对象，并绘制其结构图\n",
    "graph = builder.compile(\n",
    "    checkpointer=checkpointer,\n",
    "    store=store,\n",
    ")\n",
    "graph.get_graph().draw_png('./graph6.png')\n",
    "\n",
    "\n",
    "# 第一次交互测试：记录用户基本信息\n",
    "config1 = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
    "msg1 = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"我叫joker，喜欢学习。\"}]}, config1)\n",
    "print(\"第一次回复：\")\n",
    "msg1[\"messages\"][-1].pretty_print()\n",
    "\n",
    "\n",
    "# 第二次交互测试：验证是否能回忆起之前的信息\n",
    "config2 = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"1\"}}\n",
    "msg2 = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"我叫什么？我喜欢做什么？\"}]}, config2)\n",
    "print(\"第二次回复：\")\n",
    "msg2[\"messages\"][-1].pretty_print()\n"
   ],
   "id": "ebcf1f437915863c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一次回复：\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "哈哈，是吗? Joker 是一个很酷的名字! 我听说你喜欢学习，那就继续保持下去吧! 有什么想学的新的知识或技能呢？要不要和我一起讨论一下？\n",
      "第二次回复：\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "你好！根据我的记录，我知道你叫Joker。你很喜欢学习，这很棒！有什么可以帮助你提升知识或者解答你的问题吗？\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T03:08:13.966751Z",
     "start_time": "2025-12-17T03:08:10.365855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dotenv\n",
    "from langchain_core.messages.utils import trim_messages, count_tokens_approximately\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# 加载环境变量配置\n",
    "dotenv.load_dotenv()\n",
    "# 初始化本地大语言模型，配置模型名称和推理模式\n",
    "model = ChatOllama(\n",
    "    # model=\"deepseek-r1:32b\",\n",
    "    model=\"llama3.1:8b\",\n",
    "    base_url=\"http://localhost:12356\"\n",
    ")\n",
    "# 定义工具列表，\n",
    "tools = []\n",
    "\n",
    "\n",
    "def pre_model_hook(state):\n",
    "    \"\"\"\n",
    "    在模型处理前对消息进行预处理的钩子函数\n",
    "\n",
    "    该函数用于裁剪消息历史，只保留最近的若干条消息，避免上下文过长\n",
    "\n",
    "    Args:\n",
    "        state (dict): 包含对话状态的字典，其中\"messages\"键对应消息列表\n",
    "\n",
    "    Returns:\n",
    "        dict: 包含裁剪后消息的字典，键为\"llm_input_messages\"\n",
    "    \"\"\"\n",
    "    # 参数说明:\n",
    "    #   state[\"messages\"]: 需要裁剪的消息列表\n",
    "    #   strategy: 裁剪策略，\"last\"表示从最后开始裁剪\n",
    "    #   token_counter: 用于计算token数量的函数，这里使用近似计算方法\n",
    "    #   max_tokens: 最大token数量限制，设置为300\n",
    "    #   start_on: 开始裁剪的消息类型，\"human\"表示从人类用户的消息开始\n",
    "    #   end_on: 结束裁剪的消息类型，可以是\"human\"或\"tool\"类型的消息\n",
    "    # 返回值: 裁剪后的消息列表\n",
    "    trimmed_messages = trim_messages(\n",
    "        state[\"messages\"],\n",
    "        strategy=\"last\",\n",
    "        token_counter=count_tokens_approximately,\n",
    "        max_tokens=300,\n",
    "        start_on=\"human\",\n",
    "        end_on=(\"human\", \"tool\"),\n",
    "    )\n",
    "\n",
    "    return {\"llm_input_messages\": trimmed_messages}\n",
    "\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "agent = create_react_agent(\n",
    "    model,\n",
    "    tools,\n",
    "    pre_model_hook=pre_model_hook,\n",
    "    checkpointer=checkpointer,\n",
    ")\n",
    "config = {\"configurable\": {\"thread_id\": \"user-001\"}}\n",
    "msg1 = agent.invoke({\"messages\": [(\"user\", \"你好，我叫joker\")]}, config)\n",
    "msg1[\"messages\"][-1].pretty_print()\n",
    "like_list = ['唱', '跳', 'rap', '篮球']\n",
    "for i in like_list:\n",
    "    msg = \"我喜欢做的事是：\" + i\n",
    "    print(msg)\n",
    "    agent.invoke({\"messages\": [(\"user\", msg)]}, config)\n",
    "msg2 = agent.invoke({\"messages\": [(\"user\", \"我叫什么？我喜欢做的事是什么？\")]}, config)\n",
    "msg2[\"messages\"][-1].pretty_print()"
   ],
   "id": "bff11dc299b7dd3d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xydc\\AppData\\Local\\Temp\\ipykernel_15040\\382811284.py:52: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  agent = create_react_agent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "你好！很高兴认识你，Joker！你想和我聊什么呢？\n",
      "我喜欢做的事是：唱\n",
      "我喜欢做的事是：跳\n",
      "我喜欢做的事是：rap\n",
      "我喜欢做的事是：篮球\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "你叫 Joker，喜欢唱歌、跳舞和rap，还有篮球！\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T03:18:53.762576Z",
     "start_time": "2025-12-17T03:18:50.989300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dotenv\n",
    "from langchain_core.messages.utils import trim_messages, count_tokens_approximately\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.prebuilt.chat_agent_executor import AgentState\n",
    "from langmem.short_term import SummarizationNode, RunningSummary\n",
    "\n",
    "# 加载环境变量配置\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# 初始化本地大语言模型，配置模型名称和推理模式\n",
    "model = ChatOllama(\n",
    "    # model=\"deepseek-r1:32b\",\n",
    "    model=\"llama3.1:8b\",\n",
    "    base_url=\"http://localhost:12356\"\n",
    ")\n",
    "\n",
    "# 定义工具列表，\n",
    "tools = []\n",
    "\n",
    "# 创建一个SummarizationNode实例，用于处理文本摘要任务\n",
    "# 参数说明:\n",
    "#   token_counter: 用于估算文本token数量的函数，这里使用count_tokens_approximately函数\n",
    "#   model: 指定使用的语言模型实例\n",
    "#   max_tokens: 限制处理文本的最大token数量为300\n",
    "#   max_summary_tokens: 限制生成摘要的最大token数量为128\n",
    "#   output_messages_key: 指定输出消息在结果中的键名，设置为\"llm_input_messages\"\n",
    "summarization_node = SummarizationNode(\n",
    "    token_counter=count_tokens_approximately,\n",
    "    model=model,\n",
    "    max_tokens=300,\n",
    "    max_summary_tokens=128,\n",
    "    output_messages_key=\"llm_input_messages\",\n",
    ")\n",
    "\n",
    "\n",
    "# 自定义状态类，继承自AgentState，添加上下文字段用于存储运行时摘要信息\n",
    "class State(AgentState):\n",
    "    context: dict[str, RunningSummary]\n",
    "\n",
    "# 初始化内存检查点保存器，用于持久化代理状态\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "# 创建React代理，整合模型、工具、摘要节点和状态管理器\n",
    "agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=tools,\n",
    "    pre_model_hook=summarization_node,\n",
    "    state_schema=State,\n",
    "    checkpointer=checkpointer,\n",
    ")\n",
    "\n",
    "# 配置线程ID，用于标识用户会话\n",
    "config = {\"configurable\": {\"thread_id\": \"user-001\"}}\n",
    "\n",
    "# 启动对话，发送用户自我介绍消息并获取模型响应\n",
    "msg1 = agent.invoke({\"messages\": [(\"user\", \"你好，我叫joker\")]}, config)\n",
    "msg1[\"messages\"][-1].pretty_print()\n",
    "\n",
    "# 定义用户兴趣列表\n",
    "like_list = ['唱', '跳', 'rap', '篮球']\n",
    "\n",
    "# 循环发送用户兴趣信息，逐条更新上下文\n",
    "for i in like_list:\n",
    "    msg = \"我喜欢做的事是：\" + i\n",
    "    print(msg)\n",
    "    agent.invoke({\"messages\": [(\"user\", msg)]}, config)\n",
    "\n",
    "# 查询用户姓名和兴趣，测试模型对上下文的理解能力\n",
    "msg2 = agent.invoke({\"messages\": [(\"user\", \"我叫什么？我喜欢做的事是什么？\")]}, config)\n",
    "msg2[\"messages\"][-1].pretty_print()\n"
   ],
   "id": "67a11a3c1ff6cde9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xydc\\AppData\\Local\\Temp\\ipykernel_15040\\870486071.py:46: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  agent = create_react_agent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "嗨，Joker！我是你的聊天机器人朋友。怎么了吗？要聊天、玩游戏还是什么其他事呢？\n",
      "我喜欢做的事是：唱\n",
      "我喜欢做的事是：跳\n",
      "我喜欢做的事是：rap\n",
      "我喜欢做的事是：篮球\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "小哥，你的名字是：Joker\n",
      "你的爱好包括：\n",
      "唱歌\n",
      "跳舞\n",
      "rap\n",
      "篮球\n",
      "\n",
      "希望我没记错！\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
